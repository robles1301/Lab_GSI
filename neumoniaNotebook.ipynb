{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "075824fc-c83a-4674-a71f-1ed140fe2810",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Detección de Neumonía en Radiografías usando CNN\n",
    "**Objetivo**: Entrenar una red neuronal convolucional para clasificar imágenes en NORMAL vs. PNEUMONIA.\n",
    "**Dataset**: [Enlace al dataset de Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bdb16-9e92-49c7-8175-ed015eace97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/validation'\n",
    "test_dir = 'data/test'\n",
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5687899-810a-452d-b8df-d4cd3456ef5e",
   "metadata": {},
   "source": [
    "### Preprocesamiento de Imágenes\n",
    "- **Data Augmentation**: Aplicamos transformaciones aleatorias para evitar sobreajuste.\n",
    "- **Normalización**: Escalamos los valores de píxeles al rango [0, 1].\n",
    "- **Clases detectadas**: El generador muestra cuántas imágenes hay en cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fafe1b-c5e6-4f65-88be-4e7a8d97f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482595c4-e825-4d8a-b0cb-ef845697db79",
   "metadata": {},
   "source": [
    "### Arquitectura de la Red Neuronal Convolucional (CNN)\n",
    "\n",
    "#### Capas Utilizadas  \n",
    "1. **Capa Convolucional (`Conv2D`)**  \n",
    "   - **Función**: Detecta características locales como bordes o texturas usando filtros (kernels).  \n",
    "   - **Parámetros**:  \n",
    "     - `32/64/128 filtros`: Aumenta progresivamente la complejidad de características detectadas.  \n",
    "     - `Kernel (3,3)`: Tamaño del filtro (óptimo para imágenes de 150x150).  \n",
    "     - `activation='relu'`: Introduce no linealidad (Rectified Linear Unit), evitando el problema de vanishing gradients.  \n",
    "\n",
    "2. **Capa de Max Pooling (`MaxPooling2D`)**  \n",
    "   - **Función**: Reduce la dimensionalidad espacial (resumen de características).  \n",
    "   - **Parámetros**:  \n",
    "     - `pool_size=(2,2)`: Reduce el mapa de características a la mitad (selecciona el valor máximo en ventanas de 2x2).  \n",
    "\n",
    "3. **Capa Flatten**  \n",
    "   - **Función**: \"Aplana\" la salida 3D de las capas convolucionales a 1D para conectarse a capas densas.  \n",
    "\n",
    "4. **Capa Densa (`Dense`)**  \n",
    "   - **Función**: Neuronas totalmente conectadas para clasificación.  \n",
    "   - `512 unidades`: Suficiente capacidad para aprender patrones complejos.  \n",
    "   - `Dropout(0.5)`: Apaga el 50% de las neuronas aleatoriamente durante el entrenamiento para prevenir overfitting.  \n",
    "\n",
    "5. **Capa de Salida**  \n",
    "   - `Dense(1, activation='sigmoid')`:  \n",
    "     - **Sigmoid**: Ideal para clasificación binaria (devuelve probabilidad entre 0 y 1).  \n",
    "\n",
    "#### Compilación del Modelo  \n",
    "- **Optimizador Adam**:  \n",
    "  - `learning_rate=0.0001`: Tasa de aprendizaje pequeña para ajustes finos.  \n",
    "- **Pérdida (`binary_crossentropy`)**:  \n",
    "  - Mide el error entre predicciones y etiquetas reales en problemas binarios.  \n",
    "- **Métrica (`accuracy`)**:  \n",
    "  - Porcentaje de predicciones correctas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222b736-5b84-4305-a3ab-ff767fac391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()  # Muestra la arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67ac86-46dd-4514-8461-71e024077a15",
   "metadata": {},
   "source": [
    "### Proceso de Entrenamiento  \n",
    "\n",
    "#### Hiperparámetros Clave  \n",
    "- `batch_size=32`: Compromiso entre velocidad y estabilidad del gradiente.  \n",
    "- `epochs=10`: Número de pasadas completas sobre el dataset (puede ajustarse si hay underfitting/overfitting).  \n",
    "\n",
    "#### Generadores de Datos  \n",
    "- **`steps_per_epoch`**:  \n",
    "  - Calculado como `total_muestras // batch_size`. Ejemplo: 5216 imágenes / 32 = 163 pasos/época.  \n",
    "- **`validation_steps`**:  \n",
    "  - Misma lógica para el dataset de validación.  \n",
    "\n",
    "#### Monitoreo del Entrenamiento  \n",
    "- **Historial (`history`)**:  \n",
    "  - Almacena precisión y pérdida en entrenamiento/validación por época.  \n",
    "  - **Uso**: Para graficar curvas y diagnosticar overfitting (si val_loss sube mientras train_loss baja).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f936ac-4b20-4b6b-b9ec-de5302410107",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "model.save('modelo_neumonia.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffbf32-f987-41f3-ac6d-83672bd6db54",
   "metadata": {},
   "source": [
    "### Métricas de Rendimiento  \n",
    "\n",
    "#### 1. Gráficas de Entrenamiento  \n",
    "- **Exactitud (Accuracy)**:  \n",
    "  - Si `val_accuracy` es mucho menor que `train_accuracy` → **Overfitting**.\n",
    "- **Pérdida (Loss)**:  \n",
    "  - Pérdida en validación debería disminuir establemente.\n",
    "\n",
    "#### 2. Métricas con `sklearn.metrics`  \n",
    "- **`classification_report`**:  \n",
    "  - **Precision**: % de verdaderos positivos entre todos los positivos predichos.  \n",
    "  - **Recall**: % de verdaderos positivos detectados correctamente.  \n",
    "  - **F1-score**: Media armónica de precisión y recall (ideal para clases desbalanceadas).  \n",
    "- **`confusion_matrix`**:  \n",
    "  - Visualiza falsos positivos/negativos. Ejemplo:  \n",
    "    ```\n",
    "    [[TN FP]  \n",
    "     [FN TP]]  \n",
    "    ```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af46f0-9728-4b89-8abd-96b9fd6c71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas de precisión y pérdida\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validación')\n",
    "plt.title('Exactitud')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Métricas con sklearn\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=1,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(classification_report(test_generator.classes, predicted_classes))\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(test_generator.classes, predicted_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f1177-8e96-4534-8ab1-b4b860da7758",
   "metadata": {},
   "source": [
    "### Transfer Learning con MobileNetV2  \n",
    "\n",
    "#### ¿Por qué MobileNetV2?  \n",
    "- **Ventajas**:  \n",
    "  - Modelo preentrenado en ImageNet (aprovecha características genéricas).  \n",
    "  - Arquitectura eficiente (menos parámetros que una CNN desde cero).  \n",
    "\n",
    "#### Extracción de Características  \n",
    "1. **`include_top=False`**:  \n",
    "   - Elimina las capas densas finales de MobileNet para usar solo el extractor de características.  \n",
    "2. **`pooling='avg'`**:  \n",
    "   - Reduce la salida convolucional a un vector por imagen (Global Average Pooling).  \n",
    "\n",
    "#### Random Forest  \n",
    "- **Ventajas**:  \n",
    "  - No requiere ajuste fino de hiperparámetros (vs. SVM o redes neuronales).  \n",
    "  - Interpretabilidad (puede analizar importancia de características).  \n",
    "- **Limitaciones**:  \n",
    "  - Menos efectivo que redes neuronales si los datos son muy complejos (ej. imágenes de alta resolución).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc616bc4-c0f7-4129-a485-90edf5c78dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción de características con MobileNetV2\n",
    "mobilenet = MobileNetV2(\n",
    "    input_shape=(img_width, img_height, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "# Generar características\n",
    "train_features = mobilenet.predict(train_generator)\n",
    "test_features = mobilenet.predict(test_generator)\n",
    "\n",
    "# Entrenar Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(train_features, train_generator.classes)\n",
    "\n",
    "# Evaluar\n",
    "y_pred_rf = rf.predict(test_features)\n",
    "print(classification_report(test_generator.classes, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
